{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chap4_NLP_Kim.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1aeKOB85W8ztoO62icmXwiIpUpvGEXleq",
      "authorship_tag": "ABX9TyMWwGqByXSF2p/l9k4O+1ox",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JangSeungHyun/practice/blob/master/chap4_NLP_Kim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqMDpRyQsP53",
        "colab_type": "text"
      },
      "source": [
        "# **chap 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u56BDLpesMp8",
        "colab_type": "text"
      },
      "source": [
        "크롤링 허용여부 확인 방법\n",
        "--> 각 사이트의 robots.txt 파일 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao0VOUoaow6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://www.naver.com/robots.txt\n",
        "!cat robots.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT0Qeo_7ucIm",
        "colab_type": "text"
      },
      "source": [
        "chap 4.3 정제 - 정규표현식 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRoBfP-fppFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "regex = r\"([\\w]+\\s*:?\\s*)?\\(?\\+?([0-9]{1,3})?\\-?[0-9]{2,3}(\\)|\\-)?[0-9]{3,4}\\-?[0-9]{4}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIMfuK1Su9YC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = \"Ki: +82-10-9420-4104\"\n",
        "re.sub(regex, \"REMOVED\", x)\n",
        "#정규표현식에 해당하는 부분 치환\n",
        "\n",
        "x = \"CONTENT jiu 02)9420-4104\"\n",
        "re.sub(regex, \"REMOVED\", x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y9cvNzhvGf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = ''' abcdefg\n",
        "12345\n",
        "ab12\n",
        "a1bc2d\n",
        "12ab\n",
        "a1b\n",
        "1a2\n",
        "a1\n",
        "1a\n",
        "hijklmnop'''\n",
        "\n",
        "regex = r'([a-z])[0-9]+([a-z])'\n",
        "to = r'\\1\\2'\n",
        "\n",
        "y = '\\n'.join([re.sub(regex, to, x_i) for x_i in x.split('\\n')])\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzC2rEZRxX4V",
        "colab_type": "text"
      },
      "source": [
        "chap 4.4 문장 단위 분절"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOY9S71o1XDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHHO2_FfxPEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys, fileinput, re\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-5C_h8k2kmc",
        "colab_type": "text"
      },
      "source": [
        "**문장단위 분절**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "274zpenDyfl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__==\"__main__\":\n",
        "    line = \"자연어처리는 인공지능의 한 줄기 입니다. 시퀀스 투 시퀀스의 등장 이후로 딥러닝을 활용한 자연어처리는 새로운 전기를 맞이하게 되었습니다. 문장을 받아 단순히 수치로 나타내던 시절을 넘어, 원하는대로 문장으로 만들어낼 수 있게 된 것입니다.\"\n",
        "    if line.strip() != \"\":\n",
        "        line = re.sub(r'([a-z])\\.([A-Z])', r'\\1. \\2', line.strip())\n",
        "\n",
        "        sentences = sent_tokenize(line.strip())\n",
        "\n",
        "        for s in sentences:\n",
        "            if s != \"\":\n",
        "                sys.stdout.write(s + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGzzKr8t2qDf",
        "colab_type": "text"
      },
      "source": [
        "**문장 합치기**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxUcyi0kymMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = \"자연어처리는 인공지능의 한 줄기 입니다. 시퀀스 투 시퀀스의 등장 이후로 \\n딥러닝을 활용한 자연어처리는 새로운 전기를 맞이하게 되었습니다. 문장을 \\n받아 단순히 수치로 나타내던 시절을 넘어, 원하는대로 문장으로 만들어낼 수 \\n있게 된 것입니다.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ0iakhizkjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__=='__main__':\n",
        "    buf = []\n",
        "\n",
        "    if lines.strip() != '':\n",
        "        buf += [lines.strip('\\n').replace('\\n', ' ')]\n",
        "        print(buf)\n",
        "        sentences = sent_tokenize(\" \".join(buf))\n",
        "\n",
        "        if len(sentences) > 1:\n",
        "            buf = sentences[-1:]\n",
        "\n",
        "            sys.stdout.write('\\n'.join(sentences[:-1])+ '\\n')\n",
        "\n",
        "    sys.stdout.write(' '.join(buf)+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz3iPKmI6fDo",
        "colab_type": "text"
      },
      "source": [
        "**4.5 분절**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZdnGtqe3LTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 영어 분절 예제\n",
        "\n",
        "import sys, fileinput\n",
        "from nltk.tokenize.moses import MosesTokenizer\n",
        "\n",
        "t = MosesTokenizer()\n",
        "\n",
        "if __name__=='__main__':\n",
        "    script = 'Natural language processing is one of biggest streams in artificial intelligence, and it becomes very popular after seq2seq's invention.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4142Bgl-iwR",
        "colab_type": "text"
      },
      "source": [
        "**4.6 병렬 코퍼스 정렬**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4-kdVWM-m_H",
        "colab_type": "text"
      },
      "source": [
        "4.6.2 사전 생성\n",
        "\n",
        "병렬 코퍼스를 제작하기 위해서는 단어사전이 필요\n",
        "\n",
        "*   페이스북의 MUSE는 병렬 코퍼스가 없는 상황에서 사전 구축 방법과 코드를 제공\n",
        "*   각 단일 언어 코퍼스를 통해 구축한 언어별 단어 임베딩 벡터에 대해 다른 언어의 임베딩 벡터와 맵핑 시켜 단어 간 번역 수행\n",
        "*   MUSE는 병렬 코퍼스가 없는 상황에서도 수행할 수 있기 때문에 비지도학습이라고 할 수 있음\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb9L4KQb_tKo",
        "colab_type": "text"
      },
      "source": [
        "4.6.3 CTK을 활용한 정렬\n",
        "\n",
        "\n",
        "*   CTK(Champolian Toolkit): 이중 언어 코퍼스의 문장 정렬을 수행하는 오픈소스\n",
        "*   펄(Perl)을 사용하여 구현됨\n",
        "*   ratio parameter --> 소스언어의 캐릭터당 타깃 언어의 캐릭터 비율 의미 \n",
        "*   이를 기반으로 champolian은 문장 내 모든 단어에 대해 번역 단어를 모르더라도 문장을 정렬 할 수 있음\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwWQSZlYE8YW",
        "colab_type": "text"
      },
      "source": [
        "**4.7 서브워드 분절**\n",
        "\n",
        "*   BPE 알고리즘을 통한 서브워드 단위 분절은 현재 필수 전처리 방법으로 자리잡음\n",
        "*   서브워드 분절 기법은 이본적으로 '단어는 의미를 가진 더 작은 서브워드들의 조합으로 이루어진다'는 가정 하에 적용되는 알고리즘\n",
        "*   적절한 서브워드를 발견하여 해당단위로 쪼개주면 어휘 수를 줄일 수 있고 희소성을 효과적으로 줄일 수 있음\n",
        "*   UNK(unknown) 토큰에 대한 효율적인 대처도 가능해짐\n",
        "\n",
        "--> BPE를 적용하면 원래의 띄어쓰기 공백 외에도 BPE의 적용으로 인한 공백이 추가됨--> 구분 위해 '_'사용\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WpF7z2sGBx-",
        "colab_type": "text"
      },
      "source": [
        "**4.8 분절 복원**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPP139nZWrjM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ff0089d7-4407-4138-9112-88a58c997c9f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('perluniprops')\n",
        "nltk.download('nonbreaking_prefixes')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Package perluniprops is already up-to-date!\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2eJXNQjDMrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#분절 후처리\n",
        "import sys\n",
        "  \n",
        "import sys, fileinput\n",
        "from nltk.tokenize.moses import MosesTokenizer\n",
        "\n",
        "t = MosesTokenizer()\n",
        "STR = '＿'\n",
        "\n",
        "print(sys.argv[1])\n",
        "\n",
        "if __name__=='__main__':\n",
        "    ref_fn = '/content/drive/My Drive/project_folder/practice/input_text_en.txt'\n",
        "    f = open(ref_fn, 'r')\n",
        "\n",
        "    for line in fileinput.input(ref_fn):\n",
        "        if line.strip() != \"\":\n",
        "            tokens = t.tokenize(line.strip(), escape=False)\n",
        "\n",
        "            sys.stdout.write(\" \".join(tokens) + \"\\n\")\n",
        "        else:\n",
        "            sys.stdout.write('\\n')\n",
        "    \n",
        "\n",
        "    for ref in f:\n",
        "        ref_tokens = ref.strip().split(' ')\n",
        "        input_line = sys.stdin.readline().strip()\n",
        "\n",
        "        if input_line != \"\":\n",
        "            tokens = input_lien.split(' ')\n",
        "\n",
        "            idx = 0\n",
        "            buf = []\n",
        "\n",
        "            for ref_token in ref_tokens:\n",
        "                tmp_buf = []\n",
        "\n",
        "                while idx < len(tokens):\n",
        "                    if tokens[idx].strip() == '':\n",
        "                        idx += 1\n",
        "                        continue\n",
        "\n",
        "                    tmp_buf +=[tokens[idx]]\n",
        "                    idx += 1\n",
        "\n",
        "                    if ''.join(tmp_buf) == ref_token:\n",
        "                        break\n",
        "\n",
        "                if len(tmp_buf) > 0:\n",
        "                    buf += [STR + tmp_buf[0].strip()] + tmp_buf[1:]\n",
        "\n",
        "            sys.stdout.write(' '.join(buf) + '\\n')\n",
        "\n",
        "        else:\n",
        "            sys.stdout.write('\\n')\n",
        "        \n",
        "    f.close"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMc0jEOsTKgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}